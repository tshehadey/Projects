{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/tshehadey/Projects/blob/main/Movie%20Review%20Sentiment%20Analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tEs9MQUhLtMo"
   },
   "source": [
    "# **Sentiment Analysis on IMDB Movie Reviews**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0b3FjIB4L8eg"
   },
   "source": [
    "### **Project Overview**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "owlJcxb4MAQi"
   },
   "source": [
    "In this project, we aim to perform sentiment analysis on movie reviews from the IMDB dataset. Sentiment analysis is a common task in natural language processing (NLP) where the goal is to classify the sentiment expressed in a piece of text. Specifically, we want to determine whether a given movie review expresses a positive or negative sentiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "print(\"TensorFlow version:\", tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_datasets as tfds\n",
    "\n",
    "# The dataset contains 50,000 movie reviews with their respective sentiment labels (positive/negative)\n",
    "dataset, info = tfds.load('imdb_reviews', with_info=True, as_supervised=True)\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "train_data, test_data = dataset['train'], dataset['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the first few reviews and their corresponding labels\n",
    "for review, label in train_data.take(5):\n",
    "    print(f'Review: {review.numpy()}')\n",
    "    print(f'Label: {\"Positive\" if label.numpy() == 1 else \"Negative\"}')\n",
    "    print('---')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the distribution of labels in the training dataset\n",
    "positive_reviews = 0\n",
    "negative_reviews = 0\n",
    "\n",
    "for _, label in train_data:\n",
    "    if label.numpy() == 1:\n",
    "        positive_reviews += 1\n",
    "    else:\n",
    "        negative_reviews += 1\n",
    "\n",
    "print(f'Number of Positive Reviews: {positive_reviews}')\n",
    "print(f'Number of Negative Reviews: {negative_reviews}')\n",
    "print(f'Total Reviews: {positive_reviews + negative_reviews}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the length of the first few reviews before padding\n",
    "for review, _ in train_data.take(5):\n",
    "    print(f'Review length (before padding): {len(review.numpy())}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "review_lengths = [len(review.numpy()) for review, _ in train_data]\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(review_lengths, bins=20, color='green')\n",
    "plt.title('Distribution of Review Lengths')\n",
    "plt.xlabel('Length of Review')\n",
    "plt.ylabel('Count')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define constants\n",
    "BUFFER_SIZE = 10000\n",
    "BATCH_SIZE = 64\n",
    "VOCAB_SIZE = 10000\n",
    "\n",
    "# Build the tokenizer using the training data\n",
    "tokenizer = tfds.deprecated.text.SubwordTextEncoder.build_from_corpus(\n",
    "    (review.numpy() for review, label in train_data), target_vocab_size=VOCAB_SIZE)\n",
    "\n",
    "def encode_review(review, label):\n",
    "    encoded_review = tokenizer.encode(review.numpy())\n",
    "    encoded_review = [min(token, VOCAB_SIZE - 1) for token in encoded_review]\n",
    "    return encoded_review, label\n",
    "\n",
    "def encode_map_fn(review, label):\n",
    "    encoded_review, label = tf.py_function(encode_review, inp=[review, label], Tout=(tf.int64, tf.int64))\n",
    "    encoded_review.set_shape([None])\n",
    "    label.set_shape([])\n",
    "    return encoded_review, label\n",
    "\n",
    "# Apply the encoding function to the training and testing data\n",
    "train_data = train_data.map(encode_map_fn)\n",
    "test_data = test_data.map(encode_map_fn)\n",
    "\n",
    "# Batch and pad the datasets to ensure each batch has the same shape\n",
    "train_data = train_data.padded_batch(BATCH_SIZE, padded_shapes=([None], []))\n",
    "test_data = test_data.padded_batch(BATCH_SIZE, padded_shapes=([None], []))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the model using Sequential API\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.Input(shape=(100,)),\n",
    "    # Embedding layer converts integer sequences to dense vector representations\n",
    "    tf.keras.layers.Embedding(input_dim=VOCAB_SIZE, output_dim=64,),\n",
    "\n",
    "    # Bidirectional LSTM layers to capture information from both directions\n",
    "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64, return_sequences=True)),\n",
    "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(32)),\n",
    "\n",
    "    # Fully connected dense layer with ReLU activation\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "\n",
    "    # Output layer with sigmoid activation for binary classification\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# Compile the model with binary crossentropy loss and Adam optimizer\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the model architecture\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model for 5 epochs and validate on the test data\n",
    "history = model.fit(train_data, epochs=5, validation_data=test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training and validation accuracy\n",
    "plt.plot(history.history['accuracy'], label='accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='val_accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "plt.show()\n",
    "\n",
    "# Plot training and validation loss\n",
    "plt.plot(history.history['loss'], label='loss')\n",
    "plt.plot(history.history['val_loss'], label='val_loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model on the test data to get the accuracy\n",
    "loss, accuracy = model.evaluate(test_data)\n",
    "print(f\"Test Accuracy: {accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model in the recommended Keras format\n",
    "model.save('movie_review.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# Load the model from the .keras file\n",
    "model = load_model('movie_review.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(test_data)\n",
    "\n",
    "y_pred_classes = (y_pred > 0.5).astype(\"int32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract true labels from test_data\n",
    "y_true = []\n",
    "for _, label in test_data:\n",
    "    y_true.extend(label.numpy())\n",
    "\n",
    "import numpy as np\n",
    "# Convert to numpy array for compatibility with sklearn\n",
    "y_true = np.array(y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "# Calculate precision, recall, and F1-score\n",
    "precision = precision_score(y_true, y_pred_classes)\n",
    "recall = recall_score(y_true, y_pred_classes)\n",
    "f1 = f1_score(y_true, y_pred_classes)\n",
    "\n",
    "# Print out the metrics\n",
    "print(f\"Precision: {precision:.2f}\")\n",
    "print(f\"Recall: {recall:.2f}\")\n",
    "print(f\"F1-score: {f1:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "\n",
    "# Generate the confusion matrix\n",
    "cm = confusion_matrix(y_true, y_pred_classes)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the confusion matrix\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hK005hNSMWuD"
   },
   "source": [
    "# **Conclusion**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "noh99bwsMbh5"
   },
   "source": [
    "### **Model Performance**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZJw80knpMdZA"
   },
   "source": [
    "In this project, we successfully built and trained a deep learning model to perform sentiment analysis on the IMDB movie reviews dataset. The model achieved a test accuracy of 86.63%, which indicates a strong ability to correctly classify movie reviews as either positive or negative."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "STsOMhSPMnfH"
   },
   "source": [
    "### **Generalization to Unseen Data**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h3ViJxm8MqNY"
   },
   "source": [
    "The model demonstrates solid performance on the test data, suggesting that it has learned meaningful patterns from the training data that generalize well to unseen reviews. However, there are still opportunities for improvement, especially in fine-tuning the model to enhance precision without compromising recall."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B5pH-SJgMri4"
   },
   "source": [
    "### **Potential Next Steps**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bsnElpMXNDef"
   },
   "source": [
    "While the model generalizes well to unseen data, further improvements could be achieved through hyperparameter tuning, exploring alternative architectures like GRUs or attention mechanisms, applying data augmentation techniques to enhance diversity, and incorporating regularization methods to prevent overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U-bTd59IM2y_"
   },
   "source": [
    "### **Final Thoughts**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R2ztP8qoM37Y"
   },
   "source": [
    "This project showcases the potential of deep learning models for text classification tasks such as sentiment analysis. With further refinement, the model can be adapted and improved to achieve even better performance, making it a valuable tool for automatically assessing the sentiment expressed in text data."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
